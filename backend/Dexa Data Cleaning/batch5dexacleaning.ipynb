{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2720a3be",
   "metadata": {},
   "source": [
    "# Batch 5 DEXA Data Cleaning\n",
    "\n",
    "**Objective**: Extract and organize DEXA scan data from Batch 5 text files\n",
    "\n",
    "**Data Source**: /Sample Data/DEXA Scans/Batch 5\n",
    "\n",
    "**Output**: Organized Excel file with all measurements by subject, gender, and timepoint\n",
    "\n",
    "**Process**: Scan → Parse → Organize → Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fbb322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Data paths\n",
    "batch5_path = Path(\"/Users/aviado/Documents/GDG WashU Medicine/Sample Data/DEXA Scans/Batch 5\")\n",
    "output_dir = Path(\"../../../cleaned_output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3352715",
   "metadata": {},
   "source": [
    "## Data Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9f002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 txt files in Batch 5\n",
      "1. Pre_Scan - Male - B8M5.txt\n",
      "2. Pre_Scan - Male - B8M4.txt\n",
      "3. Pre_Scan - Male - B8M0.txt\n",
      "4. Pre_Scan - Male - B8M1.txt\n",
      "5. Pre_Scan - Male - B8M3.txt\n",
      "... and 45 more files\n"
     ]
    }
   ],
   "source": [
    "# Scan all txt files in Batch 5\n",
    "def scan_batch5_files():\n",
    "    txt_files = []\n",
    "    \n",
    "    # Define timepoint directories for Batch 5\n",
    "    timepoints = {\n",
    "        'Pre-Scan': 'Pre_Scan',\n",
    "        '1 week post-treatment': 'Week_1',\n",
    "        '2 week post-treatment': 'Week_2', \n",
    "        '3 week post-treatment': 'Week_3',\n",
    "        'Post-Scan': 'Post_Scan'\n",
    "    }\n",
    "    \n",
    "    # Scan each timepoint directory\n",
    "    for timepoint_dir, timepoint_name in timepoints.items():\n",
    "        timepoint_path = batch5_path / timepoint_dir\n",
    "        if timepoint_path.exists():\n",
    "            # Check Male and Female subdirectories\n",
    "            for gender in ['Male', 'Female']:\n",
    "                gender_path = timepoint_path / gender\n",
    "                if gender_path.exists():\n",
    "                    # Get all txt files\n",
    "                    for txt_file in gender_path.glob('*.txt'):\n",
    "                        txt_files.append({\n",
    "                            'file_path': txt_file,\n",
    "                            'timepoint': timepoint_name,\n",
    "                            'gender': gender,\n",
    "                            'filename': txt_file.name\n",
    "                        })\n",
    "    \n",
    "    # Also check root directory for any txt files\n",
    "    for txt_file in batch5_path.glob('*.txt'):\n",
    "        txt_files.append({\n",
    "            'file_path': txt_file,\n",
    "            'timepoint': 'Root',\n",
    "            'gender': 'Unknown',\n",
    "            'filename': txt_file.name\n",
    "        })\n",
    "    \n",
    "    return txt_files\n",
    "\n",
    "# Scan files\n",
    "batch5_files = scan_batch5_files()\n",
    "print(f\"Found {len(batch5_files)} txt files in Batch 5\")\n",
    "\n",
    "# Show sample of found files\n",
    "for i, file_info in enumerate(batch5_files[:5]):\n",
    "    print(f\"{i+1}. {file_info['timepoint']} - {file_info['gender']} - {file_info['filename']}\")\n",
    "if len(batch5_files) > 5:\n",
    "    print(f\"... and {len(batch5_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94499648",
   "metadata": {},
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9688fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample parsing result:\n",
      "File: B8M5.txt\n",
      "  subject_id: M5\n",
      "  sample_area: 33.523\n",
      "  bone_area: 11.435\n",
      "  total_weight: 34.0742\n",
      "  soft_weight: 32.8412\n",
      "  lean_weight: 22.4615\n",
      "  fat_weight: 10.3796\n",
      "  fat_percent: 31.606\n",
      "  bmc: 1.23304\n",
      "  bmd: 107.831\n"
     ]
    }
   ],
   "source": [
    "# Parse DEXA txt file content\n",
    "def parse_dexa_txt(file_path):\n",
    "    \"\"\"Extract measurements from DEXA txt file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract subject ID from filename (adapt for Batch 5 naming)\n",
    "        filename = file_path.name\n",
    "        subject_match = re.search(r'(B5_[MF]_\\d+)', filename)\n",
    "        if not subject_match:\n",
    "            # Try alternative patterns for Batch 5\n",
    "            subject_match = re.search(r'([MF]\\d+)', filename)\n",
    "        subject_id = subject_match.group(1) if subject_match else filename.replace('.txt', '')\n",
    "        \n",
    "        # Extract measurements using regex patterns\n",
    "        measurements = {'subject_id': subject_id}\n",
    "        \n",
    "        # Find WHOLE TISSUE STATISTICS section (more comprehensive data)\n",
    "        whole_section = re.search(r'WHOLE TISSUE STATISTICS:(.*?)(?=\\n\\s*-|$)', content, re.DOTALL)\n",
    "        if whole_section:\n",
    "            section_text = whole_section.group(1)\n",
    "        else:\n",
    "            # Fallback to INSIDE ROI if WHOLE not found\n",
    "            section_text = content\n",
    "        \n",
    "        # Define patterns for key measurements\n",
    "        patterns = {\n",
    "            'sample_area': r'Sample Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'bone_area': r'Bone Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'total_weight': r'Total Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'soft_weight': r'Soft Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'lean_weight': r'Lean Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_weight': r'Fat Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_percent': r'Fat Percent:\\s*([\\d.]+)',\n",
    "            'bmc': r'BMC:\\s*([\\d.]+)\\s*g',\n",
    "            'bmd': r'BMD:\\s*([\\d.]+)\\s*mg/cm'\n",
    "        }\n",
    "        \n",
    "        # Extract each measurement\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, section_text)\n",
    "            if match:\n",
    "                measurements[key] = float(match.group(1))\n",
    "            else:\n",
    "                measurements[key] = None\n",
    "        \n",
    "        return measurements\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test parsing with first file\n",
    "if batch5_files:\n",
    "    sample_file = batch5_files[0]['file_path']\n",
    "    sample_data = parse_dexa_txt(sample_file)\n",
    "    print(f\"Sample parsing result:\")\n",
    "    print(f\"File: {sample_file.name}\")\n",
    "    for key, value in sample_data.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb501fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 50 files\n",
      "Columns: ['subject_id', 'sample_area', 'bone_area', 'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent', 'bmc', 'bmd', 'batch', 'timepoint', 'gender', 'filename']\n",
      "Shape: (50, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>sample_area</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>batch</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M5</td>\n",
       "      <td>33.523</td>\n",
       "      <td>11.435</td>\n",
       "      <td>34.0742</td>\n",
       "      <td>32.8412</td>\n",
       "      <td>22.4615</td>\n",
       "      <td>10.3796</td>\n",
       "      <td>31.606</td>\n",
       "      <td>1.23304</td>\n",
       "      <td>107.831</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M5.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M4</td>\n",
       "      <td>33.005</td>\n",
       "      <td>12.317</td>\n",
       "      <td>34.0905</td>\n",
       "      <td>32.6383</td>\n",
       "      <td>22.9954</td>\n",
       "      <td>9.6428</td>\n",
       "      <td>29.545</td>\n",
       "      <td>1.45228</td>\n",
       "      <td>117.908</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0</td>\n",
       "      <td>37.423</td>\n",
       "      <td>12.678</td>\n",
       "      <td>40.0617</td>\n",
       "      <td>38.7079</td>\n",
       "      <td>28.1945</td>\n",
       "      <td>10.5133</td>\n",
       "      <td>27.161</td>\n",
       "      <td>1.35384</td>\n",
       "      <td>106.786</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1</td>\n",
       "      <td>36.142</td>\n",
       "      <td>11.126</td>\n",
       "      <td>39.6344</td>\n",
       "      <td>38.4868</td>\n",
       "      <td>30.1166</td>\n",
       "      <td>8.3702</td>\n",
       "      <td>21.748</td>\n",
       "      <td>1.14761</td>\n",
       "      <td>103.150</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M3</td>\n",
       "      <td>32.174</td>\n",
       "      <td>10.797</td>\n",
       "      <td>32.9502</td>\n",
       "      <td>31.8330</td>\n",
       "      <td>22.5268</td>\n",
       "      <td>9.3062</td>\n",
       "      <td>29.234</td>\n",
       "      <td>1.11723</td>\n",
       "      <td>103.480</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  sample_area  bone_area  total_weight  soft_weight  lean_weight  \\\n",
       "0         M5       33.523     11.435       34.0742      32.8412      22.4615   \n",
       "1         M4       33.005     12.317       34.0905      32.6383      22.9954   \n",
       "2         M0       37.423     12.678       40.0617      38.7079      28.1945   \n",
       "3         M1       36.142     11.126       39.6344      38.4868      30.1166   \n",
       "4         M3       32.174     10.797       32.9502      31.8330      22.5268   \n",
       "\n",
       "   fat_weight  fat_percent      bmc      bmd    batch timepoint gender  \\\n",
       "0     10.3796       31.606  1.23304  107.831  Batch_5  Pre_Scan   Male   \n",
       "1      9.6428       29.545  1.45228  117.908  Batch_5  Pre_Scan   Male   \n",
       "2     10.5133       27.161  1.35384  106.786  Batch_5  Pre_Scan   Male   \n",
       "3      8.3702       21.748  1.14761  103.150  Batch_5  Pre_Scan   Male   \n",
       "4      9.3062       29.234  1.11723  103.480  Batch_5  Pre_Scan   Male   \n",
       "\n",
       "   filename  \n",
       "0  B8M5.txt  \n",
       "1  B8M4.txt  \n",
       "2  B8M0.txt  \n",
       "3  B8M1.txt  \n",
       "4  B8M3.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process all Batch 5 files\n",
    "def process_all_batch5_files():\n",
    "    all_data = []\n",
    "    \n",
    "    for file_info in batch5_files:\n",
    "        # Parse the txt file\n",
    "        measurements = parse_dexa_txt(file_info['file_path'])\n",
    "        \n",
    "        if measurements:\n",
    "            # Add metadata\n",
    "            measurements.update({\n",
    "                'batch': 'Batch_5',\n",
    "                'timepoint': file_info['timepoint'], \n",
    "                'gender': file_info['gender'],\n",
    "                'filename': file_info['filename']\n",
    "            })\n",
    "            all_data.append(measurements)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Process all files\n",
    "batch5_df = process_all_batch5_files()\n",
    "\n",
    "print(f\"Processed {len(batch5_df)} files\")\n",
    "print(f\"Columns: {list(batch5_df.columns)}\")\n",
    "print(f\"Shape: {batch5_df.shape}\")\n",
    "\n",
    "# Show sample data\n",
    "batch5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917e1e5",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bde428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 Data Summary:\n",
      "Total subjects: 10\n",
      "Timepoints: ['Pre_Scan' 'Week_1' 'Week_2' 'Week_3' 'Post_Scan']\n",
      "Gender distribution: {'Male': 30, 'Female': 20}\n",
      "\n",
      "Missing values in key measurements:\n",
      "\n",
      "Subject longitudinal tracking:\n",
      "Subjects with multiple timepoints: 10\n",
      "Most tracked subject has 5 timepoints\n",
      "\n",
      "Scans by timepoint and gender:\n",
      "gender     Female  Male\n",
      "timepoint              \n",
      "Post_Scan       4     6\n",
      "Pre_Scan        4     6\n",
      "Week_1          4     6\n",
      "Week_2          4     6\n",
      "Week_3          4     6\n"
     ]
    }
   ],
   "source": [
    "# Analyze the organized data\n",
    "print(\"Batch 5 Data Summary:\")\n",
    "print(f\"Total subjects: {batch5_df['subject_id'].nunique()}\")\n",
    "print(f\"Timepoints: {batch5_df['timepoint'].unique()}\")\n",
    "print(f\"Gender distribution: {batch5_df['gender'].value_counts().to_dict()}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = batch5_df.isnull().sum()\n",
    "numeric_cols = batch5_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nMissing values in key measurements:\")\n",
    "for col in numeric_cols:\n",
    "    if missing_data[col] > 0:\n",
    "        print(f\"  {col}: {missing_data[col]} missing\")\n",
    "\n",
    "# Subject tracking across timepoints\n",
    "subject_timepoints = batch5_df.groupby('subject_id')['timepoint'].nunique().sort_values(ascending=False)\n",
    "print(f\"\\nSubject longitudinal tracking:\")\n",
    "print(f\"Subjects with multiple timepoints: {len(subject_timepoints[subject_timepoints > 1])}\")\n",
    "print(f\"Most tracked subject has {subject_timepoints.iloc[0]} timepoints\")\n",
    "\n",
    "# Show distribution by timepoint and gender\n",
    "timepoint_gender = batch5_df.groupby(['timepoint', 'gender']).size().unstack(fill_value=0)\n",
    "print(f\"\\nScans by timepoint and gender:\")\n",
    "print(timepoint_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0116d75",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7c68ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete\n",
      "Missing values remaining: 0\n",
      "Final shape: (50, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>sample_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batch_5</td>\n",
       "      <td>M5</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M5.txt</td>\n",
       "      <td>34.0742</td>\n",
       "      <td>32.8412</td>\n",
       "      <td>22.4615</td>\n",
       "      <td>10.3796</td>\n",
       "      <td>31.606</td>\n",
       "      <td>1.23304</td>\n",
       "      <td>107.831</td>\n",
       "      <td>11.435</td>\n",
       "      <td>33.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batch_5</td>\n",
       "      <td>M4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M4.txt</td>\n",
       "      <td>34.0905</td>\n",
       "      <td>32.6383</td>\n",
       "      <td>22.9954</td>\n",
       "      <td>9.6428</td>\n",
       "      <td>29.545</td>\n",
       "      <td>1.45228</td>\n",
       "      <td>117.908</td>\n",
       "      <td>12.317</td>\n",
       "      <td>33.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batch_5</td>\n",
       "      <td>M0</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M0.txt</td>\n",
       "      <td>40.0617</td>\n",
       "      <td>38.7079</td>\n",
       "      <td>28.1945</td>\n",
       "      <td>10.5133</td>\n",
       "      <td>27.161</td>\n",
       "      <td>1.35384</td>\n",
       "      <td>106.786</td>\n",
       "      <td>12.678</td>\n",
       "      <td>37.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batch_5</td>\n",
       "      <td>M1</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M1.txt</td>\n",
       "      <td>39.6344</td>\n",
       "      <td>38.4868</td>\n",
       "      <td>30.1166</td>\n",
       "      <td>8.3702</td>\n",
       "      <td>21.748</td>\n",
       "      <td>1.14761</td>\n",
       "      <td>103.150</td>\n",
       "      <td>11.126</td>\n",
       "      <td>36.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch_5</td>\n",
       "      <td>M3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B8M3.txt</td>\n",
       "      <td>32.9502</td>\n",
       "      <td>31.8330</td>\n",
       "      <td>22.5268</td>\n",
       "      <td>9.3062</td>\n",
       "      <td>29.234</td>\n",
       "      <td>1.11723</td>\n",
       "      <td>103.480</td>\n",
       "      <td>10.797</td>\n",
       "      <td>32.174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch subject_id timepoint gender  filename  total_weight  soft_weight  \\\n",
       "0  Batch_5         M5  Pre_Scan   Male  B8M5.txt       34.0742      32.8412   \n",
       "1  Batch_5         M4  Pre_Scan   Male  B8M4.txt       34.0905      32.6383   \n",
       "2  Batch_5         M0  Pre_Scan   Male  B8M0.txt       40.0617      38.7079   \n",
       "3  Batch_5         M1  Pre_Scan   Male  B8M1.txt       39.6344      38.4868   \n",
       "4  Batch_5         M3  Pre_Scan   Male  B8M3.txt       32.9502      31.8330   \n",
       "\n",
       "   lean_weight  fat_weight  fat_percent      bmc      bmd  bone_area  \\\n",
       "0      22.4615     10.3796       31.606  1.23304  107.831     11.435   \n",
       "1      22.9954      9.6428       29.545  1.45228  117.908     12.317   \n",
       "2      28.1945     10.5133       27.161  1.35384  106.786     12.678   \n",
       "3      30.1166      8.3702       21.748  1.14761  103.150     11.126   \n",
       "4      22.5268      9.3062       29.234  1.11723  103.480     10.797   \n",
       "\n",
       "   sample_area  \n",
       "0       33.523  \n",
       "1       33.005  \n",
       "2       37.423  \n",
       "3       36.142  \n",
       "4       32.174  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the Batch 5 dataset\n",
    "def clean_batch5_data(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Fill missing numeric values with median (more appropriate for DEXA measurements)\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            if df_clean[col].notna().sum() > 0:\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            else:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "    \n",
    "    # Fill missing categorical values\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col] = df_clean[col].fillna(\"Unknown\")\n",
    "    \n",
    "    # Organize columns in logical order\n",
    "    column_order = [\n",
    "        'batch', 'subject_id', 'timepoint', 'gender', 'filename',\n",
    "        'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent',\n",
    "        'bmc', 'bmd', 'bone_area', 'sample_area'\n",
    "    ]\n",
    "    \n",
    "    # Reorder columns (keep any extra columns at the end)\n",
    "    available_cols = [col for col in column_order if col in df_clean.columns]\n",
    "    extra_cols = [col for col in df_clean.columns if col not in column_order]\n",
    "    df_clean = df_clean[available_cols + extra_cols]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "batch5_cleaned = clean_batch5_data(batch5_df)\n",
    "\n",
    "print(f\"Data cleaning complete\")\n",
    "print(f\"Missing values remaining: {batch5_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"Final shape: {batch5_cleaned.shape}\")\n",
    "\n",
    "# Show cleaned data sample\n",
    "batch5_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df918092",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e85133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file exported: ../../../cleaned_output/batch5_dexa_cleaned.xlsx\n",
      "Sheets created: Batch5_All_Data, Timepoint_Summary, Subject_Summary\n",
      "CSV backup saved: ../../../cleaned_output/batch5_dexa_cleaned.csv\n",
      "\n",
      "Final Results Summary:\n",
      "- Total records: 50\n",
      "- Unique subjects: 10\n",
      "- Timepoints: ['Pre_Scan', 'Week_1', 'Week_2', 'Week_3', 'Post_Scan']\n",
      "- Gender distribution: {'Male': 30, 'Female': 20}\n",
      "- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel with multiple sheets\n",
    "excel_output_path = output_dir / \"batch5_dexa_cleaned.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_output_path, engine='openpyxl') as writer:\n",
    "    # Main data sheet\n",
    "    batch5_cleaned.to_excel(writer, sheet_name='Batch5_All_Data', index=False)\n",
    "    \n",
    "    # Summary by timepoint\n",
    "    timepoint_summary = batch5_cleaned.groupby(['timepoint', 'gender']).agg({\n",
    "        'subject_id': 'nunique',\n",
    "        'total_weight': 'mean',\n",
    "        'fat_percent': 'mean',\n",
    "        'bmd': 'mean',\n",
    "        'lean_weight': 'mean'\n",
    "    }).round(3)\n",
    "    timepoint_summary.to_excel(writer, sheet_name='Timepoint_Summary')\n",
    "    \n",
    "    # Subject tracking sheet\n",
    "    subject_summary = batch5_cleaned.groupby('subject_id').agg({\n",
    "        'timepoint': 'nunique',\n",
    "        'gender': 'first',\n",
    "        'total_weight': ['min', 'max', 'mean'],\n",
    "        'fat_percent': ['min', 'max', 'mean']\n",
    "    }).round(3)\n",
    "    subject_summary.columns = ['_'.join(col).strip() for col in subject_summary.columns]\n",
    "    subject_summary.to_excel(writer, sheet_name='Subject_Summary')\n",
    "\n",
    "print(f\"Excel file exported: {excel_output_path}\")\n",
    "print(f\"Sheets created: Batch5_All_Data, Timepoint_Summary, Subject_Summary\")\n",
    "\n",
    "# Also save as CSV for backup\n",
    "csv_output_path = output_dir / \"batch5_dexa_cleaned.csv\"\n",
    "batch5_cleaned.to_csv(csv_output_path, index=False)\n",
    "print(f\"CSV backup saved: {csv_output_path}\")\n",
    "\n",
    "print(f\"\\nFinal Results Summary:\")\n",
    "print(f\"- Total records: {len(batch5_cleaned)}\")\n",
    "print(f\"- Unique subjects: {batch5_cleaned['subject_id'].nunique()}\")\n",
    "print(f\"- Timepoints: {list(batch5_cleaned['timepoint'].unique())}\")\n",
    "print(f\"- Gender distribution: {batch5_cleaned['gender'].value_counts().to_dict()}\")\n",
    "print(f\"- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
