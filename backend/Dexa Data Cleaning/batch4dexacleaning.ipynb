{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a253197",
   "metadata": {},
   "source": [
    "# Batch 4 DEXA Data Cleaning\n",
    "\n",
    "**Objective**: Extract and organize DEXA scan data from Batch 4 text files\n",
    "\n",
    "**Data Source**: /Sample Data/DEXA Scans/Batch 4\n",
    "\n",
    "**Output**: Organized Excel file with all measurements by subject, gender, and timepoint\n",
    "\n",
    "**Process**: Scan → Parse → Organize → Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e9fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Data paths\n",
    "batch4_path = Path(\"/Users/aviado/Documents/GDG WashU Medicine/Sample Data/DEXA Scans/Batch 4\")\n",
    "output_dir = Path(\"../../../cleaned_output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339570d6",
   "metadata": {},
   "source": [
    "## Data Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0cdfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 txt files in Batch 4\n",
      "1. Pre_Scan - Male - B4_M_2.txt\n",
      "2. Pre_Scan - Male - B4_M_3.txt\n",
      "3. Pre_Scan - Male - B4_M_1.txt\n",
      "4. Pre_Scan - Male - B4_M_0.txt\n",
      "5. Pre_Scan - Male - B4_M_4.txt\n",
      "... and 42 more files\n"
     ]
    }
   ],
   "source": [
    "# Scan all txt files in Batch 4\n",
    "def scan_batch4_files():\n",
    "    txt_files = []\n",
    "    \n",
    "    # Define timepoint directories for Batch 4\n",
    "    timepoints = {\n",
    "        'Pre-Scan': 'Pre_Scan',\n",
    "        '1 week post-treatment': 'Week_1',\n",
    "        '2 weeks post-treatment': 'Week_2', \n",
    "        '3 weeks post-treatment': 'Week_3',\n",
    "        'Post-scan': 'Post_Scan'\n",
    "    }\n",
    "    \n",
    "    # Scan each timepoint directory\n",
    "    for timepoint_dir, timepoint_name in timepoints.items():\n",
    "        timepoint_path = batch4_path / timepoint_dir\n",
    "        if timepoint_path.exists():\n",
    "            # Check Male and Female subdirectories\n",
    "            for gender in ['Male', 'Female']:\n",
    "                gender_path = timepoint_path / gender\n",
    "                if gender_path.exists():\n",
    "                    # Get all txt files\n",
    "                    for txt_file in gender_path.glob('*.txt'):\n",
    "                        txt_files.append({\n",
    "                            'file_path': txt_file,\n",
    "                            'timepoint': timepoint_name,\n",
    "                            'gender': gender,\n",
    "                            'filename': txt_file.name\n",
    "                        })\n",
    "    \n",
    "    # Also check root directory for any txt files\n",
    "    for txt_file in batch4_path.glob('*.txt'):\n",
    "        txt_files.append({\n",
    "            'file_path': txt_file,\n",
    "            'timepoint': 'Root',\n",
    "            'gender': 'Unknown',\n",
    "            'filename': txt_file.name\n",
    "        })\n",
    "    \n",
    "    return txt_files\n",
    "\n",
    "# Scan files\n",
    "batch4_files = scan_batch4_files()\n",
    "print(f\"Found {len(batch4_files)} txt files in Batch 4\")\n",
    "\n",
    "# Show sample of found files\n",
    "for i, file_info in enumerate(batch4_files[:5]):\n",
    "    print(f\"{i+1}. {file_info['timepoint']} - {file_info['gender']} - {file_info['filename']}\")\n",
    "if len(batch4_files) > 5:\n",
    "    print(f\"... and {len(batch4_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2438816",
   "metadata": {},
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0476496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample parsing result:\n",
      "File: B4_M_2.txt\n",
      "  subject_id: B4_M_2\n",
      "  sample_area: 31.079\n",
      "  bone_area: 8.944\n",
      "  total_weight: 31.8933\n",
      "  soft_weight: 31.2364\n",
      "  lean_weight: 23.2806\n",
      "  fat_weight: 7.9558\n",
      "  fat_percent: 25.47\n",
      "  bmc: 0.65686\n",
      "  bmd: 73.446\n"
     ]
    }
   ],
   "source": [
    "# Parse DEXA txt file content\n",
    "def parse_dexa_txt(file_path):\n",
    "    \"\"\"Extract measurements from DEXA txt file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract subject ID from filename (adapt for Batch 4 naming)\n",
    "        filename = file_path.name\n",
    "        subject_match = re.search(r'(B4_[MF]_\\d+)', filename)\n",
    "        if not subject_match:\n",
    "            # Try alternative patterns for Batch 4\n",
    "            subject_match = re.search(r'([MF]\\d+)', filename)\n",
    "        subject_id = subject_match.group(1) if subject_match else filename.replace('.txt', '')\n",
    "        \n",
    "        # Extract measurements using regex patterns\n",
    "        measurements = {'subject_id': subject_id}\n",
    "        \n",
    "        # Find WHOLE TISSUE STATISTICS section (more comprehensive data)\n",
    "        whole_section = re.search(r'WHOLE TISSUE STATISTICS:(.*?)(?=\\n\\s*-|$)', content, re.DOTALL)\n",
    "        if whole_section:\n",
    "            section_text = whole_section.group(1)\n",
    "        else:\n",
    "            # Fallback to INSIDE ROI if WHOLE not found\n",
    "            section_text = content\n",
    "        \n",
    "        # Define patterns for key measurements\n",
    "        patterns = {\n",
    "            'sample_area': r'Sample Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'bone_area': r'Bone Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'total_weight': r'Total Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'soft_weight': r'Soft Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'lean_weight': r'Lean Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_weight': r'Fat Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_percent': r'Fat Percent:\\s*([\\d.]+)',\n",
    "            'bmc': r'BMC:\\s*([\\d.]+)\\s*g',\n",
    "            'bmd': r'BMD:\\s*([\\d.]+)\\s*mg/cm'\n",
    "        }\n",
    "        \n",
    "        # Extract each measurement\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, section_text)\n",
    "            if match:\n",
    "                measurements[key] = float(match.group(1))\n",
    "            else:\n",
    "                measurements[key] = None\n",
    "        \n",
    "        return measurements\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test parsing with first file\n",
    "if batch4_files:\n",
    "    sample_file = batch4_files[0]['file_path']\n",
    "    sample_data = parse_dexa_txt(sample_file)\n",
    "    print(f\"Sample parsing result:\")\n",
    "    print(f\"File: {sample_file.name}\")\n",
    "    for key, value in sample_data.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bc25d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 47 files\n",
      "Columns: ['subject_id', 'sample_area', 'bone_area', 'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent', 'bmc', 'bmd', 'batch', 'timepoint', 'gender', 'filename']\n",
      "Shape: (47, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>sample_area</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>batch</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B4_M_2</td>\n",
       "      <td>31.079</td>\n",
       "      <td>8.944</td>\n",
       "      <td>31.8933</td>\n",
       "      <td>31.2364</td>\n",
       "      <td>23.2806</td>\n",
       "      <td>7.9558</td>\n",
       "      <td>25.470</td>\n",
       "      <td>0.65686</td>\n",
       "      <td>73.446</td>\n",
       "      <td>Batch_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B4_M_3</td>\n",
       "      <td>32.921</td>\n",
       "      <td>9.455</td>\n",
       "      <td>34.7664</td>\n",
       "      <td>34.0095</td>\n",
       "      <td>25.1797</td>\n",
       "      <td>8.8298</td>\n",
       "      <td>25.963</td>\n",
       "      <td>0.75694</td>\n",
       "      <td>80.054</td>\n",
       "      <td>Batch_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B4_M_1</td>\n",
       "      <td>33.178</td>\n",
       "      <td>10.401</td>\n",
       "      <td>33.2410</td>\n",
       "      <td>32.2550</td>\n",
       "      <td>24.6999</td>\n",
       "      <td>7.5551</td>\n",
       "      <td>23.423</td>\n",
       "      <td>0.98604</td>\n",
       "      <td>94.799</td>\n",
       "      <td>Batch_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B4_M_0</td>\n",
       "      <td>32.612</td>\n",
       "      <td>11.143</td>\n",
       "      <td>35.5652</td>\n",
       "      <td>34.4501</td>\n",
       "      <td>25.0691</td>\n",
       "      <td>9.3810</td>\n",
       "      <td>27.231</td>\n",
       "      <td>1.11502</td>\n",
       "      <td>100.066</td>\n",
       "      <td>Batch_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B4_M_4</td>\n",
       "      <td>30.297</td>\n",
       "      <td>9.402</td>\n",
       "      <td>31.5731</td>\n",
       "      <td>30.8248</td>\n",
       "      <td>22.4249</td>\n",
       "      <td>8.3999</td>\n",
       "      <td>27.250</td>\n",
       "      <td>0.74839</td>\n",
       "      <td>79.599</td>\n",
       "      <td>Batch_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  sample_area  bone_area  total_weight  soft_weight  lean_weight  \\\n",
       "0     B4_M_2       31.079      8.944       31.8933      31.2364      23.2806   \n",
       "1     B4_M_3       32.921      9.455       34.7664      34.0095      25.1797   \n",
       "2     B4_M_1       33.178     10.401       33.2410      32.2550      24.6999   \n",
       "3     B4_M_0       32.612     11.143       35.5652      34.4501      25.0691   \n",
       "4     B4_M_4       30.297      9.402       31.5731      30.8248      22.4249   \n",
       "\n",
       "   fat_weight  fat_percent      bmc      bmd    batch timepoint gender  \\\n",
       "0      7.9558       25.470  0.65686   73.446  Batch_4  Pre_Scan   Male   \n",
       "1      8.8298       25.963  0.75694   80.054  Batch_4  Pre_Scan   Male   \n",
       "2      7.5551       23.423  0.98604   94.799  Batch_4  Pre_Scan   Male   \n",
       "3      9.3810       27.231  1.11502  100.066  Batch_4  Pre_Scan   Male   \n",
       "4      8.3999       27.250  0.74839   79.599  Batch_4  Pre_Scan   Male   \n",
       "\n",
       "     filename  \n",
       "0  B4_M_2.txt  \n",
       "1  B4_M_3.txt  \n",
       "2  B4_M_1.txt  \n",
       "3  B4_M_0.txt  \n",
       "4  B4_M_4.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process all Batch 4 files\n",
    "def process_all_batch4_files():\n",
    "    all_data = []\n",
    "    \n",
    "    for file_info in batch4_files:\n",
    "        # Parse the txt file\n",
    "        measurements = parse_dexa_txt(file_info['file_path'])\n",
    "        \n",
    "        if measurements:\n",
    "            # Add metadata\n",
    "            measurements.update({\n",
    "                'batch': 'Batch_4',\n",
    "                'timepoint': file_info['timepoint'], \n",
    "                'gender': file_info['gender'],\n",
    "                'filename': file_info['filename']\n",
    "            })\n",
    "            all_data.append(measurements)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Process all files\n",
    "batch4_df = process_all_batch4_files()\n",
    "\n",
    "print(f\"Processed {len(batch4_df)} files\")\n",
    "print(f\"Columns: {list(batch4_df.columns)}\")\n",
    "print(f\"Shape: {batch4_df.shape}\")\n",
    "\n",
    "# Show sample data\n",
    "batch4_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2530d",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d07ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 Data Summary:\n",
      "Total subjects: 10\n",
      "Timepoints: ['Pre_Scan' 'Week_1' 'Week_2' 'Week_3' 'Post_Scan']\n",
      "Gender distribution: {'Female': 25, 'Male': 22}\n",
      "\n",
      "Missing values in key measurements:\n",
      "\n",
      "Subject longitudinal tracking:\n",
      "Subjects with multiple timepoints: 10\n",
      "Most tracked subject has 5 timepoints\n",
      "\n",
      "Scans by timepoint and gender:\n",
      "gender     Female  Male\n",
      "timepoint              \n",
      "Post_Scan       5     4\n",
      "Pre_Scan        5     5\n",
      "Week_1          5     5\n",
      "Week_2          5     4\n",
      "Week_3          5     4\n"
     ]
    }
   ],
   "source": [
    "# Analyze the organized data\n",
    "print(\"Batch 4 Data Summary:\")\n",
    "print(f\"Total subjects: {batch4_df['subject_id'].nunique()}\")\n",
    "print(f\"Timepoints: {batch4_df['timepoint'].unique()}\")\n",
    "print(f\"Gender distribution: {batch4_df['gender'].value_counts().to_dict()}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = batch4_df.isnull().sum()\n",
    "numeric_cols = batch4_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nMissing values in key measurements:\")\n",
    "for col in numeric_cols:\n",
    "    if missing_data[col] > 0:\n",
    "        print(f\"  {col}: {missing_data[col]} missing\")\n",
    "\n",
    "# Subject tracking across timepoints\n",
    "subject_timepoints = batch4_df.groupby('subject_id')['timepoint'].nunique().sort_values(ascending=False)\n",
    "print(f\"\\nSubject longitudinal tracking:\")\n",
    "print(f\"Subjects with multiple timepoints: {len(subject_timepoints[subject_timepoints > 1])}\")\n",
    "print(f\"Most tracked subject has {subject_timepoints.iloc[0]} timepoints\")\n",
    "\n",
    "# Show distribution by timepoint and gender\n",
    "timepoint_gender = batch4_df.groupby(['timepoint', 'gender']).size().unstack(fill_value=0)\n",
    "print(f\"\\nScans by timepoint and gender:\")\n",
    "print(timepoint_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113e6fe",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47382f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete\n",
      "Missing values remaining: 0\n",
      "Final shape: (47, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>sample_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batch_4</td>\n",
       "      <td>B4_M_2</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_2.txt</td>\n",
       "      <td>31.8933</td>\n",
       "      <td>31.2364</td>\n",
       "      <td>23.2806</td>\n",
       "      <td>7.9558</td>\n",
       "      <td>25.470</td>\n",
       "      <td>0.65686</td>\n",
       "      <td>73.446</td>\n",
       "      <td>8.944</td>\n",
       "      <td>31.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batch_4</td>\n",
       "      <td>B4_M_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_3.txt</td>\n",
       "      <td>34.7664</td>\n",
       "      <td>34.0095</td>\n",
       "      <td>25.1797</td>\n",
       "      <td>8.8298</td>\n",
       "      <td>25.963</td>\n",
       "      <td>0.75694</td>\n",
       "      <td>80.054</td>\n",
       "      <td>9.455</td>\n",
       "      <td>32.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batch_4</td>\n",
       "      <td>B4_M_1</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_1.txt</td>\n",
       "      <td>33.2410</td>\n",
       "      <td>32.2550</td>\n",
       "      <td>24.6999</td>\n",
       "      <td>7.5551</td>\n",
       "      <td>23.423</td>\n",
       "      <td>0.98604</td>\n",
       "      <td>94.799</td>\n",
       "      <td>10.401</td>\n",
       "      <td>33.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batch_4</td>\n",
       "      <td>B4_M_0</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_0.txt</td>\n",
       "      <td>35.5652</td>\n",
       "      <td>34.4501</td>\n",
       "      <td>25.0691</td>\n",
       "      <td>9.3810</td>\n",
       "      <td>27.231</td>\n",
       "      <td>1.11502</td>\n",
       "      <td>100.066</td>\n",
       "      <td>11.143</td>\n",
       "      <td>32.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch_4</td>\n",
       "      <td>B4_M_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B4_M_4.txt</td>\n",
       "      <td>31.5731</td>\n",
       "      <td>30.8248</td>\n",
       "      <td>22.4249</td>\n",
       "      <td>8.3999</td>\n",
       "      <td>27.250</td>\n",
       "      <td>0.74839</td>\n",
       "      <td>79.599</td>\n",
       "      <td>9.402</td>\n",
       "      <td>30.297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch subject_id timepoint gender    filename  total_weight  soft_weight  \\\n",
       "0  Batch_4     B4_M_2  Pre_Scan   Male  B4_M_2.txt       31.8933      31.2364   \n",
       "1  Batch_4     B4_M_3  Pre_Scan   Male  B4_M_3.txt       34.7664      34.0095   \n",
       "2  Batch_4     B4_M_1  Pre_Scan   Male  B4_M_1.txt       33.2410      32.2550   \n",
       "3  Batch_4     B4_M_0  Pre_Scan   Male  B4_M_0.txt       35.5652      34.4501   \n",
       "4  Batch_4     B4_M_4  Pre_Scan   Male  B4_M_4.txt       31.5731      30.8248   \n",
       "\n",
       "   lean_weight  fat_weight  fat_percent      bmc      bmd  bone_area  \\\n",
       "0      23.2806      7.9558       25.470  0.65686   73.446      8.944   \n",
       "1      25.1797      8.8298       25.963  0.75694   80.054      9.455   \n",
       "2      24.6999      7.5551       23.423  0.98604   94.799     10.401   \n",
       "3      25.0691      9.3810       27.231  1.11502  100.066     11.143   \n",
       "4      22.4249      8.3999       27.250  0.74839   79.599      9.402   \n",
       "\n",
       "   sample_area  \n",
       "0       31.079  \n",
       "1       32.921  \n",
       "2       33.178  \n",
       "3       32.612  \n",
       "4       30.297  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the Batch 4 dataset\n",
    "def clean_batch4_data(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Fill missing numeric values with median (more appropriate for DEXA measurements)\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            if df_clean[col].notna().sum() > 0:\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            else:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "    \n",
    "    # Fill missing categorical values\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col] = df_clean[col].fillna(\"Unknown\")\n",
    "    \n",
    "    # Organize columns in logical order\n",
    "    column_order = [\n",
    "        'batch', 'subject_id', 'timepoint', 'gender', 'filename',\n",
    "        'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent',\n",
    "        'bmc', 'bmd', 'bone_area', 'sample_area'\n",
    "    ]\n",
    "    \n",
    "    # Reorder columns (keep any extra columns at the end)\n",
    "    available_cols = [col for col in column_order if col in df_clean.columns]\n",
    "    extra_cols = [col for col in df_clean.columns if col not in column_order]\n",
    "    df_clean = df_clean[available_cols + extra_cols]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "batch4_cleaned = clean_batch4_data(batch4_df)\n",
    "\n",
    "print(f\"Data cleaning complete\")\n",
    "print(f\"Missing values remaining: {batch4_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"Final shape: {batch4_cleaned.shape}\")\n",
    "\n",
    "# Show cleaned data sample\n",
    "batch4_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5975d72",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69449ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file exported: ../../../cleaned_output/batch4_dexa_cleaned.xlsx\n",
      "Sheets created: Batch4_All_Data, Timepoint_Summary, Subject_Summary\n",
      "CSV backup saved: ../../../cleaned_output/batch4_dexa_cleaned.csv\n",
      "\n",
      "Final Results Summary:\n",
      "- Total records: 47\n",
      "- Unique subjects: 10\n",
      "- Timepoints: ['Pre_Scan', 'Week_1', 'Week_2', 'Week_3', 'Post_Scan']\n",
      "- Gender distribution: {'Female': 25, 'Male': 22}\n",
      "- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel with multiple sheets\n",
    "excel_output_path = output_dir / \"batch4_dexa_cleaned.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_output_path, engine='openpyxl') as writer:\n",
    "    # Main data sheet\n",
    "    batch4_cleaned.to_excel(writer, sheet_name='Batch4_All_Data', index=False)\n",
    "    \n",
    "    # Summary by timepoint\n",
    "    timepoint_summary = batch4_cleaned.groupby(['timepoint', 'gender']).agg({\n",
    "        'subject_id': 'nunique',\n",
    "        'total_weight': 'mean',\n",
    "        'fat_percent': 'mean',\n",
    "        'bmd': 'mean',\n",
    "        'lean_weight': 'mean'\n",
    "    }).round(3)\n",
    "    timepoint_summary.to_excel(writer, sheet_name='Timepoint_Summary')\n",
    "    \n",
    "    # Subject tracking sheet\n",
    "    subject_summary = batch4_cleaned.groupby('subject_id').agg({\n",
    "        'timepoint': 'nunique',\n",
    "        'gender': 'first',\n",
    "        'total_weight': ['min', 'max', 'mean'],\n",
    "        'fat_percent': ['min', 'max', 'mean']\n",
    "    }).round(3)\n",
    "    subject_summary.columns = ['_'.join(col).strip() for col in subject_summary.columns]\n",
    "    subject_summary.to_excel(writer, sheet_name='Subject_Summary')\n",
    "\n",
    "print(f\"Excel file exported: {excel_output_path}\")\n",
    "print(f\"Sheets created: Batch4_All_Data, Timepoint_Summary, Subject_Summary\")\n",
    "\n",
    "# Also save as CSV for backup\n",
    "csv_output_path = output_dir / \"batch4_dexa_cleaned.csv\"\n",
    "batch4_cleaned.to_csv(csv_output_path, index=False)\n",
    "print(f\"CSV backup saved: {csv_output_path}\")\n",
    "\n",
    "print(f\"\\nFinal Results Summary:\")\n",
    "print(f\"- Total records: {len(batch4_cleaned)}\")\n",
    "print(f\"- Unique subjects: {batch4_cleaned['subject_id'].nunique()}\")\n",
    "print(f\"- Timepoints: {list(batch4_cleaned['timepoint'].unique())}\")\n",
    "print(f\"- Gender distribution: {batch4_cleaned['gender'].value_counts().to_dict()}\")\n",
    "print(f\"- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
