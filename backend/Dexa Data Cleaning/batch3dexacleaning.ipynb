{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719c5200",
   "metadata": {},
   "source": [
    "# Batch 3 DEXA Data Cleaning\n",
    "\n",
    "**Objective**: Extract and organize DEXA scan data from Batch 3 text files\n",
    "\n",
    "**Data Source**: /Sample Data/DEXA Scans/Batch 3\n",
    "\n",
    "**Output**: Organized Excel file with all measurements by subject, gender, and timepoint\n",
    "\n",
    "**Process**: Scan → Parse → Organize → Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42168b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Data paths\n",
    "batch3_path = Path(\"/Users/aviado/Documents/GDG WashU Medicine/Sample Data/DEXA Scans/Batch 3\")\n",
    "output_dir = Path(\"../../../cleaned_output\")\n",
    "output_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba3b92",
   "metadata": {},
   "source": [
    "## Data Scanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f321cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 txt files in Batch 3\n",
      "1. Pre_Scan - Male - B3_M_0.txt\n",
      "2. Pre_Scan - Male - B3_M_1.txt\n",
      "3. Pre_Scan - Male - B3_M_3.txt\n",
      "4. Pre_Scan - Male - B3_M_2.txt\n",
      "5. Pre_Scan - Male - B3_M_4.txt\n",
      "... and 43 more files\n"
     ]
    }
   ],
   "source": [
    "# Scan all txt files in Batch 3\n",
    "def scan_batch3_files():\n",
    "    txt_files = []\n",
    "    \n",
    "    # Define timepoint directories for Batch 3\n",
    "    timepoints = {\n",
    "        'Pre-Scan': 'Pre_Scan',\n",
    "        '1 week post-treatment': 'Week_1',\n",
    "        '2 week post-treatment': 'Week_2', \n",
    "        '3 week post-treatment': 'Week_3',\n",
    "        'Post-scan': 'Post_Scan'\n",
    "    }\n",
    "    \n",
    "    # Scan each timepoint directory\n",
    "    for timepoint_dir, timepoint_name in timepoints.items():\n",
    "        timepoint_path = batch3_path / timepoint_dir\n",
    "        if timepoint_path.exists():\n",
    "            # Check Male and Female subdirectories\n",
    "            for gender in ['Male', 'Female']:\n",
    "                gender_path = timepoint_path / gender\n",
    "                if gender_path.exists():\n",
    "                    # Get all txt files\n",
    "                    for txt_file in gender_path.glob('*.txt'):\n",
    "                        txt_files.append({\n",
    "                            'file_path': txt_file,\n",
    "                            'timepoint': timepoint_name,\n",
    "                            'gender': gender,\n",
    "                            'filename': txt_file.name\n",
    "                        })\n",
    "    \n",
    "    # Also check root directory for any txt files\n",
    "    for txt_file in batch3_path.glob('*.txt'):\n",
    "        txt_files.append({\n",
    "            'file_path': txt_file,\n",
    "            'timepoint': 'Root',\n",
    "            'gender': 'Unknown',\n",
    "            'filename': txt_file.name\n",
    "        })\n",
    "    \n",
    "    return txt_files\n",
    "\n",
    "# Scan files\n",
    "batch3_files = scan_batch3_files()\n",
    "print(f\"Found {len(batch3_files)} txt files in Batch 3\")\n",
    "\n",
    "# Show sample of found files\n",
    "for i, file_info in enumerate(batch3_files[:5]):\n",
    "    print(f\"{i+1}. {file_info['timepoint']} - {file_info['gender']} - {file_info['filename']}\")\n",
    "if len(batch3_files) > 5:\n",
    "    print(f\"... and {len(batch3_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477ff98",
   "metadata": {},
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538e7045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample parsing result:\n",
      "File: B3_M_0.txt\n",
      "  subject_id: B3_M_0\n",
      "  sample_area: 35.091\n",
      "  bone_area: 10.221\n",
      "  total_weight: 35.5679\n",
      "  soft_weight: 34.7521\n",
      "  lean_weight: 23.7603\n",
      "  fat_weight: 10.9918\n",
      "  fat_percent: 31.629\n",
      "  bmc: 0.81583\n",
      "  bmd: 79.823\n"
     ]
    }
   ],
   "source": [
    "# Parse DEXA txt file content\n",
    "def parse_dexa_txt(file_path):\n",
    "    \"\"\"Extract measurements from DEXA txt file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Extract subject ID from filename (adapt for Batch 3 naming)\n",
    "        filename = file_path.name\n",
    "        subject_match = re.search(r'(B3_[MF]_\\d+)', filename)\n",
    "        if not subject_match:\n",
    "            # Try alternative patterns for Batch 3\n",
    "            subject_match = re.search(r'([MF]\\d+)', filename)\n",
    "        subject_id = subject_match.group(1) if subject_match else filename.replace('.txt', '')\n",
    "        \n",
    "        # Extract measurements using regex patterns\n",
    "        measurements = {'subject_id': subject_id}\n",
    "        \n",
    "        # Find WHOLE TISSUE STATISTICS section (more comprehensive data)\n",
    "        whole_section = re.search(r'WHOLE TISSUE STATISTICS:(.*?)(?=\\n\\s*-|$)', content, re.DOTALL)\n",
    "        if whole_section:\n",
    "            section_text = whole_section.group(1)\n",
    "        else:\n",
    "            # Fallback to INSIDE ROI if WHOLE not found\n",
    "            section_text = content\n",
    "        \n",
    "        # Define patterns for key measurements\n",
    "        patterns = {\n",
    "            'sample_area': r'Sample Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'bone_area': r'Bone Area:\\s*([\\d.]+)\\s*cm',\n",
    "            'total_weight': r'Total Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'soft_weight': r'Soft Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'lean_weight': r'Lean Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_weight': r'Fat Weight:\\s*([\\d.]+)\\s*g',\n",
    "            'fat_percent': r'Fat Percent:\\s*([\\d.]+)',\n",
    "            'bmc': r'BMC:\\s*([\\d.]+)\\s*g',\n",
    "            'bmd': r'BMD:\\s*([\\d.]+)\\s*mg/cm'\n",
    "        }\n",
    "        \n",
    "        # Extract each measurement\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, section_text)\n",
    "            if match:\n",
    "                measurements[key] = float(match.group(1))\n",
    "            else:\n",
    "                measurements[key] = None\n",
    "        \n",
    "        return measurements\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test parsing with first file\n",
    "if batch3_files:\n",
    "    sample_file = batch3_files[0]['file_path']\n",
    "    sample_data = parse_dexa_txt(sample_file)\n",
    "    print(f\"Sample parsing result:\")\n",
    "    print(f\"File: {sample_file.name}\")\n",
    "    for key, value in sample_data.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de1555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 48 files\n",
      "Columns: ['subject_id', 'sample_area', 'bone_area', 'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent', 'bmc', 'bmd', 'batch', 'timepoint', 'gender', 'filename']\n",
      "Shape: (48, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>sample_area</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>batch</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B3_M_0</td>\n",
       "      <td>35.091</td>\n",
       "      <td>10.221</td>\n",
       "      <td>35.5679</td>\n",
       "      <td>34.7521</td>\n",
       "      <td>23.7603</td>\n",
       "      <td>10.9918</td>\n",
       "      <td>31.629</td>\n",
       "      <td>0.81583</td>\n",
       "      <td>79.823</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B3_M_1</td>\n",
       "      <td>37.581</td>\n",
       "      <td>11.712</td>\n",
       "      <td>37.4815</td>\n",
       "      <td>36.3929</td>\n",
       "      <td>24.4471</td>\n",
       "      <td>11.9458</td>\n",
       "      <td>32.824</td>\n",
       "      <td>1.08861</td>\n",
       "      <td>92.950</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B3_M_3</td>\n",
       "      <td>34.005</td>\n",
       "      <td>10.678</td>\n",
       "      <td>35.2593</td>\n",
       "      <td>34.2374</td>\n",
       "      <td>21.9613</td>\n",
       "      <td>12.2760</td>\n",
       "      <td>35.856</td>\n",
       "      <td>1.02190</td>\n",
       "      <td>95.698</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B3_M_2</td>\n",
       "      <td>35.085</td>\n",
       "      <td>11.210</td>\n",
       "      <td>37.1200</td>\n",
       "      <td>36.1086</td>\n",
       "      <td>22.4425</td>\n",
       "      <td>13.6662</td>\n",
       "      <td>37.847</td>\n",
       "      <td>1.01141</td>\n",
       "      <td>90.226</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B3_M_4</td>\n",
       "      <td>34.495</td>\n",
       "      <td>11.583</td>\n",
       "      <td>35.7049</td>\n",
       "      <td>34.6436</td>\n",
       "      <td>23.5031</td>\n",
       "      <td>11.1406</td>\n",
       "      <td>32.158</td>\n",
       "      <td>1.06125</td>\n",
       "      <td>91.620</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  sample_area  bone_area  total_weight  soft_weight  lean_weight  \\\n",
       "0     B3_M_0       35.091     10.221       35.5679      34.7521      23.7603   \n",
       "1     B3_M_1       37.581     11.712       37.4815      36.3929      24.4471   \n",
       "2     B3_M_3       34.005     10.678       35.2593      34.2374      21.9613   \n",
       "3     B3_M_2       35.085     11.210       37.1200      36.1086      22.4425   \n",
       "4     B3_M_4       34.495     11.583       35.7049      34.6436      23.5031   \n",
       "\n",
       "   fat_weight  fat_percent      bmc     bmd    batch timepoint gender  \\\n",
       "0     10.9918       31.629  0.81583  79.823  Batch_3  Pre_Scan   Male   \n",
       "1     11.9458       32.824  1.08861  92.950  Batch_3  Pre_Scan   Male   \n",
       "2     12.2760       35.856  1.02190  95.698  Batch_3  Pre_Scan   Male   \n",
       "3     13.6662       37.847  1.01141  90.226  Batch_3  Pre_Scan   Male   \n",
       "4     11.1406       32.158  1.06125  91.620  Batch_3  Pre_Scan   Male   \n",
       "\n",
       "     filename  \n",
       "0  B3_M_0.txt  \n",
       "1  B3_M_1.txt  \n",
       "2  B3_M_3.txt  \n",
       "3  B3_M_2.txt  \n",
       "4  B3_M_4.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process all Batch 3 files\n",
    "def process_all_batch3_files():\n",
    "    all_data = []\n",
    "    \n",
    "    for file_info in batch3_files:\n",
    "        # Parse the txt file\n",
    "        measurements = parse_dexa_txt(file_info['file_path'])\n",
    "        \n",
    "        if measurements:\n",
    "            # Add metadata\n",
    "            measurements.update({\n",
    "                'batch': 'Batch_3',\n",
    "                'timepoint': file_info['timepoint'], \n",
    "                'gender': file_info['gender'],\n",
    "                'filename': file_info['filename']\n",
    "            })\n",
    "            all_data.append(measurements)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Process all files\n",
    "batch3_df = process_all_batch3_files()\n",
    "\n",
    "print(f\"Processed {len(batch3_df)} files\")\n",
    "print(f\"Columns: {list(batch3_df.columns)}\")\n",
    "print(f\"Shape: {batch3_df.shape}\")\n",
    "\n",
    "# Show sample data\n",
    "batch3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb97a51",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a02871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 Data Summary:\n",
      "Total subjects: 10\n",
      "Timepoints: ['Pre_Scan' 'Week_1' 'Week_2' 'Week_3' 'Post_Scan']\n",
      "Gender distribution: {'Male': 25, 'Female': 23}\n",
      "\n",
      "Missing values in key measurements:\n",
      "\n",
      "Subject longitudinal tracking:\n",
      "Subjects with multiple timepoints: 10\n",
      "Most tracked subject has 5 timepoints\n",
      "\n",
      "Scans by timepoint and gender:\n",
      "gender     Female  Male\n",
      "timepoint              \n",
      "Post_Scan       4     4\n",
      "Pre_Scan        5     5\n",
      "Week_1          5     5\n",
      "Week_2          5     6\n",
      "Week_3          4     5\n"
     ]
    }
   ],
   "source": [
    "# Analyze the organized data\n",
    "print(\"Batch 3 Data Summary:\")\n",
    "print(f\"Total subjects: {batch3_df['subject_id'].nunique()}\")\n",
    "print(f\"Timepoints: {batch3_df['timepoint'].unique()}\")\n",
    "print(f\"Gender distribution: {batch3_df['gender'].value_counts().to_dict()}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = batch3_df.isnull().sum()\n",
    "numeric_cols = batch3_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nMissing values in key measurements:\")\n",
    "for col in numeric_cols:\n",
    "    if missing_data[col] > 0:\n",
    "        print(f\"  {col}: {missing_data[col]} missing\")\n",
    "\n",
    "# Subject tracking across timepoints\n",
    "subject_timepoints = batch3_df.groupby('subject_id')['timepoint'].nunique().sort_values(ascending=False)\n",
    "print(f\"\\nSubject longitudinal tracking:\")\n",
    "print(f\"Subjects with multiple timepoints: {len(subject_timepoints[subject_timepoints > 1])}\")\n",
    "print(f\"Most tracked subject has {subject_timepoints.iloc[0]} timepoints\")\n",
    "\n",
    "# Show distribution by timepoint and gender\n",
    "timepoint_gender = batch3_df.groupby(['timepoint', 'gender']).size().unstack(fill_value=0)\n",
    "print(f\"\\nScans by timepoint and gender:\")\n",
    "print(timepoint_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f33669",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55043df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete\n",
      "Missing values remaining: 0\n",
      "Final shape: (48, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>gender</th>\n",
       "      <th>filename</th>\n",
       "      <th>total_weight</th>\n",
       "      <th>soft_weight</th>\n",
       "      <th>lean_weight</th>\n",
       "      <th>fat_weight</th>\n",
       "      <th>fat_percent</th>\n",
       "      <th>bmc</th>\n",
       "      <th>bmd</th>\n",
       "      <th>bone_area</th>\n",
       "      <th>sample_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batch_3</td>\n",
       "      <td>B3_M_0</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_0.txt</td>\n",
       "      <td>35.5679</td>\n",
       "      <td>34.7521</td>\n",
       "      <td>23.7603</td>\n",
       "      <td>10.9918</td>\n",
       "      <td>31.629</td>\n",
       "      <td>0.81583</td>\n",
       "      <td>79.823</td>\n",
       "      <td>10.221</td>\n",
       "      <td>35.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batch_3</td>\n",
       "      <td>B3_M_1</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_1.txt</td>\n",
       "      <td>37.4815</td>\n",
       "      <td>36.3929</td>\n",
       "      <td>24.4471</td>\n",
       "      <td>11.9458</td>\n",
       "      <td>32.824</td>\n",
       "      <td>1.08861</td>\n",
       "      <td>92.950</td>\n",
       "      <td>11.712</td>\n",
       "      <td>37.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batch_3</td>\n",
       "      <td>B3_M_3</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_3.txt</td>\n",
       "      <td>35.2593</td>\n",
       "      <td>34.2374</td>\n",
       "      <td>21.9613</td>\n",
       "      <td>12.2760</td>\n",
       "      <td>35.856</td>\n",
       "      <td>1.02190</td>\n",
       "      <td>95.698</td>\n",
       "      <td>10.678</td>\n",
       "      <td>34.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batch_3</td>\n",
       "      <td>B3_M_2</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_2.txt</td>\n",
       "      <td>37.1200</td>\n",
       "      <td>36.1086</td>\n",
       "      <td>22.4425</td>\n",
       "      <td>13.6662</td>\n",
       "      <td>37.847</td>\n",
       "      <td>1.01141</td>\n",
       "      <td>90.226</td>\n",
       "      <td>11.210</td>\n",
       "      <td>35.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batch_3</td>\n",
       "      <td>B3_M_4</td>\n",
       "      <td>Pre_Scan</td>\n",
       "      <td>Male</td>\n",
       "      <td>B3_M_4.txt</td>\n",
       "      <td>35.7049</td>\n",
       "      <td>34.6436</td>\n",
       "      <td>23.5031</td>\n",
       "      <td>11.1406</td>\n",
       "      <td>32.158</td>\n",
       "      <td>1.06125</td>\n",
       "      <td>91.620</td>\n",
       "      <td>11.583</td>\n",
       "      <td>34.495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batch subject_id timepoint gender    filename  total_weight  soft_weight  \\\n",
       "0  Batch_3     B3_M_0  Pre_Scan   Male  B3_M_0.txt       35.5679      34.7521   \n",
       "1  Batch_3     B3_M_1  Pre_Scan   Male  B3_M_1.txt       37.4815      36.3929   \n",
       "2  Batch_3     B3_M_3  Pre_Scan   Male  B3_M_3.txt       35.2593      34.2374   \n",
       "3  Batch_3     B3_M_2  Pre_Scan   Male  B3_M_2.txt       37.1200      36.1086   \n",
       "4  Batch_3     B3_M_4  Pre_Scan   Male  B3_M_4.txt       35.7049      34.6436   \n",
       "\n",
       "   lean_weight  fat_weight  fat_percent      bmc     bmd  bone_area  \\\n",
       "0      23.7603     10.9918       31.629  0.81583  79.823     10.221   \n",
       "1      24.4471     11.9458       32.824  1.08861  92.950     11.712   \n",
       "2      21.9613     12.2760       35.856  1.02190  95.698     10.678   \n",
       "3      22.4425     13.6662       37.847  1.01141  90.226     11.210   \n",
       "4      23.5031     11.1406       32.158  1.06125  91.620     11.583   \n",
       "\n",
       "   sample_area  \n",
       "0       35.091  \n",
       "1       37.581  \n",
       "2       34.005  \n",
       "3       35.085  \n",
       "4       34.495  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the Batch 3 dataset\n",
    "def clean_batch3_data(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Fill missing numeric values with median (more appropriate for DEXA measurements)\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            if df_clean[col].notna().sum() > 0:\n",
    "                median_val = df_clean[col].median()\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            else:\n",
    "                df_clean[col] = df_clean[col].fillna(0)\n",
    "    \n",
    "    # Fill missing categorical values\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col] = df_clean[col].fillna(\"Unknown\")\n",
    "    \n",
    "    # Organize columns in logical order\n",
    "    column_order = [\n",
    "        'batch', 'subject_id', 'timepoint', 'gender', 'filename',\n",
    "        'total_weight', 'soft_weight', 'lean_weight', 'fat_weight', 'fat_percent',\n",
    "        'bmc', 'bmd', 'bone_area', 'sample_area'\n",
    "    ]\n",
    "    \n",
    "    # Reorder columns (keep any extra columns at the end)\n",
    "    available_cols = [col for col in column_order if col in df_clean.columns]\n",
    "    extra_cols = [col for col in df_clean.columns if col not in column_order]\n",
    "    df_clean = df_clean[available_cols + extra_cols]\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "batch3_cleaned = clean_batch3_data(batch3_df)\n",
    "\n",
    "print(f\"Data cleaning complete\")\n",
    "print(f\"Missing values remaining: {batch3_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"Final shape: {batch3_cleaned.shape}\")\n",
    "\n",
    "# Show cleaned data sample\n",
    "batch3_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f68eae",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdeac15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file exported: ../../../cleaned_output/batch3_dexa_cleaned.xlsx\n",
      "Sheets created: Batch3_All_Data, Timepoint_Summary, Subject_Summary\n",
      "CSV backup saved: ../../../cleaned_output/batch3_dexa_cleaned.csv\n",
      "\n",
      "Final Results Summary:\n",
      "- Total records: 48\n",
      "- Unique subjects: 10\n",
      "- Timepoints: ['Pre_Scan', 'Week_1', 'Week_2', 'Week_3', 'Post_Scan']\n",
      "- Gender distribution: {'Male': 25, 'Female': 23}\n",
      "- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\n"
     ]
    }
   ],
   "source": [
    "# Export to Excel with multiple sheets\n",
    "excel_output_path = output_dir / \"batch3_dexa_cleaned.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(excel_output_path, engine='openpyxl') as writer:\n",
    "    # Main data sheet\n",
    "    batch3_cleaned.to_excel(writer, sheet_name='Batch3_All_Data', index=False)\n",
    "    \n",
    "    # Summary by timepoint\n",
    "    timepoint_summary = batch3_cleaned.groupby(['timepoint', 'gender']).agg({\n",
    "        'subject_id': 'nunique',\n",
    "        'total_weight': 'mean',\n",
    "        'fat_percent': 'mean',\n",
    "        'bmd': 'mean',\n",
    "        'lean_weight': 'mean'\n",
    "    }).round(3)\n",
    "    timepoint_summary.to_excel(writer, sheet_name='Timepoint_Summary')\n",
    "    \n",
    "    # Subject tracking sheet\n",
    "    subject_summary = batch3_cleaned.groupby('subject_id').agg({\n",
    "        'timepoint': 'nunique',\n",
    "        'gender': 'first',\n",
    "        'total_weight': ['min', 'max', 'mean'],\n",
    "        'fat_percent': ['min', 'max', 'mean']\n",
    "    }).round(3)\n",
    "    subject_summary.columns = ['_'.join(col).strip() for col in subject_summary.columns]\n",
    "    subject_summary.to_excel(writer, sheet_name='Subject_Summary')\n",
    "\n",
    "print(f\"Excel file exported: {excel_output_path}\")\n",
    "print(f\"Sheets created: Batch3_All_Data, Timepoint_Summary, Subject_Summary\")\n",
    "\n",
    "# Also save as CSV for backup\n",
    "csv_output_path = output_dir / \"batch3_dexa_cleaned.csv\"\n",
    "batch3_cleaned.to_csv(csv_output_path, index=False)\n",
    "print(f\"CSV backup saved: {csv_output_path}\")\n",
    "\n",
    "print(f\"\\nFinal Results Summary:\")\n",
    "print(f\"- Total records: {len(batch3_cleaned)}\")\n",
    "print(f\"- Unique subjects: {batch3_cleaned['subject_id'].nunique()}\")\n",
    "print(f\"- Timepoints: {list(batch3_cleaned['timepoint'].unique())}\")\n",
    "print(f\"- Gender distribution: {batch3_cleaned['gender'].value_counts().to_dict()}\")\n",
    "print(f\"- Key measurements: total_weight, fat_percent, bmd, lean_weight, fat_weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
